
## 一、哈希字面量
什么是哈希表？在我看来，就是键值对的集合。但是由于算法的约束，有时不同的值会对应相同的键，会造成哈希碰撞。monkey语言的哈希表如下：
```go
>> let myHash = {"name": "Jimmy", "age": 72, "band": "Led Zeppelin"};
>> myHash["name"]
Jimmy
>> myHash["age"]
72
>> myHash["band"]
Led Zeppelin

//又如
>> let myHash = {true: "yes, a boolean", 99: "correct, an integer"};
>> myHash[true]
yes, a boolean
>> myHash[99]
correct, an integer
>> myHash[5 > 1]
yes, a boolean
>> myHash[100 - 1]
correct, an integer
```
### 1.1 词法分析
这个相符简单，只需要在token里加入`:`并且在词法器加入对应的解析即可。
```go
//token.go
// 声明一些词法常量
const (
	// 特殊类型
	ILLEGAL = "ILLEGAL" // 未知字符
	EOF     = "EOF"     // 文件结尾

	// 标识符+字面量
	IDENT = "IDENT" // add, foobar, x, y
	INT   = "INT"   // 1343456

	// 运算符
	ASSIGN   = "="
	PLUS     = "+"
	MINUS    = "-"
	BANG     = "!"
	ASTERISK = "*"
	SLASH    = "/"

	// 分隔符
	COMMA     = ","
	SEMICOLON = ";"

	LT       = "<"
	GT       = ">"
	LPAREN   = "("
	RPAREN   = ")"
	LBRACE   = "{"
	RBRACE   = "}"
	LBRACKET = "["
	RBRACKET = "]"

	// 关键字
	FUNCTION = "FUNCTION"
	LET      = "LET"
	//*********
	IF     = "IF"
	ELIF   = "ELIF"
	ELSE   = "ELSE"
	RETURN = "RETURN"
	TRUE   = "TRUE"
	FALSE  = "FALSE"

	//比较运算符
	EQ     = "=="
	NOT_EQ = "!="

	//字符串
	STRING = "STRING"

	//ToDo
	//逻辑运算符
	AND = "&&" //和
	OR  = "||" //或

	//
	COLON = ":"
)
```
词法器改动如下：
```go
//lexer.go
// 根据当前的ch创建词法单元，匹配对应的Type和字面量Literal
func (l *Lexer) NextToken() token.Token {
	var tok token.Token

	l.skipWhitespace() //跳过空格和一些

	switch l.ch {
	case '=':
		if l.peekChar() == '=' { //特殊处理 等于==
			ch := l.ch
			l.readChar()
			literal := string(ch) + string(l.ch)
			tok = token.Token{Type: token.EQ, Literal: literal}
		} else {
			tok = newToken(token.ASSIGN, l.ch)
		}
	case ';':
		tok = newToken(token.SEMICOLON, l.ch)
	case '(':
		tok = newToken(token.LPAREN, l.ch)
	case ')':
		tok = newToken(token.RPAREN, l.ch)
	case ',':
		tok = newToken(token.COMMA, l.ch)
	case '+':
		tok = newToken(token.PLUS, l.ch)
	case '{':
		tok = newToken(token.LBRACE, l.ch)
	case '}':
		tok = newToken(token.RBRACE, l.ch)
	//！-/*5；
	//			5 < 10 > 5;
	case '!':
		if l.peekChar() == '=' { //特殊处理 不等于！=
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //！=
			tok = token.Token{Type: token.NOT_EQ, Literal: literal}
		} else {
			tok = newToken(token.BANG, l.ch)
		}
	case '-':
		tok = newToken(token.MINUS, l.ch)
	case '*':
		tok = newToken(token.ASTERISK, l.ch)
	case '/':
		tok = newToken(token.SLASH, l.ch)
	case '<':
		tok = newToken(token.LT, l.ch)
	case '>':
		tok = newToken(token.GT, l.ch)

	case 0:
		tok.Literal = ""
		tok.Type = token.EOF

	case '"':
		tok.Type = token.STRING
		tok.Literal = l.readString()

	//Todo
	//逻辑运算符
	case '&': //与运算
		if l.peekChar() == '&' {
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //&&
			tok = token.Token{Type: token.AND, Literal: literal}
		} else {
			tok.Literal = ""
			tok.Type = token.EOF
		}
	case '|': //或运算
		if l.peekChar() == '|' {
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //||
			tok = token.Token{Type: token.OR, Literal: literal}
		} else {
			tok.Literal = ""
			tok.Type = token.EOF
		}
	case '[':
		tok = newToken(token.LBRACKET, l.ch)
	case ']':
		tok = newToken(token.RBRACKET, l.ch)
	case ':':
		tok = newToken(token.COLON, l.ch)

	//检查是否是标识符
	default:
		if isLetter(l.ch) { //判断是否是字母
			tok.Literal = l.readIdentifier()          //字面量indent
			tok.Type = token.LookupIdent(tok.Literal) //检查关键字
			return tok
		} else if isDigit(l.ch) { //检查是否是数字
			tok.Type = token.INT
			tok.Literal = l.readNumber()
			return tok
		} else {
			tok = newToken(token.ILLEGAL, l.ch)
		}
	}

	l.readChar()
	return tok
}
```
测试代码如下：
```go
//lexer_test.go
func TestNextToken(t *testing.T) {
	input := `let five = 5;
let ten = 10;

let add = fn(x, y) {
  x + y;
};

let result = add(five, ten);
!-/*5;
5 < 10 > 5;

if (5 < 10) {
	return true;
} elif(5==10) {
	return false;
}
10 == 10;
10 != 9;
"foobar"
"foo bar"
&&
||
[1,2]
{"foo":"bar"}
`

	tests := []struct {
		expectedType    token.TokenType
		expectedLiteral string
	}{
		{token.LET, "let"},
		{token.IDENT, "five"},
		{token.ASSIGN, "="},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "ten"},
		{token.ASSIGN, "="},
		{token.INT, "10"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "add"},
		{token.ASSIGN, "="},
		{token.FUNCTION, "fn"},
		{token.LPAREN, "("},
		{token.IDENT, "x"},
		{token.COMMA, ","},
		{token.IDENT, "y"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.IDENT, "x"},
		{token.PLUS, "+"},
		{token.IDENT, "y"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "result"},
		{token.ASSIGN, "="},
		{token.IDENT, "add"},
		{token.LPAREN, "("},
		{token.IDENT, "five"},
		{token.COMMA, ","},
		{token.IDENT, "ten"},
		{token.RPAREN, ")"},
		{token.SEMICOLON, ";"},
		{token.BANG, "!"},
		{token.MINUS, "-"},
		{token.SLASH, "/"},
		{token.ASTERISK, "*"},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.INT, "5"},
		{token.LT, "<"},
		{token.INT, "10"},
		{token.GT, ">"},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.IF, "if"},
		{token.LPAREN, "("},
		{token.INT, "5"},
		{token.LT, "<"},
		{token.INT, "10"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RETURN, "return"},
		{token.TRUE, "true"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.ELIF, "elif"},
		{token.LPAREN, "("},
		{token.INT, "5"},
		{token.EQ, "=="},
		{token.INT, "10"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RETURN, "return"},
		{token.FALSE, "false"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.INT, "10"},
		{token.EQ, "=="},
		{token.INT, "10"},
		{token.SEMICOLON, ";"},
		{token.INT, "10"},
		{token.NOT_EQ, "!="},
		{token.INT, "9"},
		{token.SEMICOLON, ";"},
		{token.STRING, "foobar"},
		{token.STRING, "foo bar"},
		{token.AND, "&&"},
		{token.OR, "||"},
		{token.LBRACKET, "["},
		{token.INT, "1"},
		{token.COMMA, ","},
		{token.INT, "2"},
		{token.RBRACKET, "]"},
		{token.LBRACE, "{"},
		{token.STRING, "foo"},
		{token.COLON, ":"},
		{token.STRING, "bar"},
		{token.RBRACE, "}"},
		{token.EOF, ""},
	}

	// 创建词法分析器实例
	l := New(input) //lexer

	//i：表示当前tests中的位置。
	//tt：表示当前迭代的expectedType（词法单元类型）和expectedLiteral（字面量）字段。
	for i, tt := range tests {

		// 调用词法分析器的NextToken方法获取下一个词法单元
		tok := l.NextToken() //token

		// 检查实际的词法单元类型是否与预期的类型一致
		if tok.Type != tt.expectedType {
			t.Fatalf("tests[%d] - tokentype wrong. expected=%q, got==%q", i, tt.expectedType, tok.Type)
		}
		// 检查实际的词法单元字面量是否与预期的字面量一致
		if tok.Literal != tt.expectedLiteral {
			t.Fatalf("tests[%d] - literal wrong. expected=%q, got==%q", i, tt.expectedLiteral, tok.Literal)
		}
	}

}
```
### 1.2 语法分析
语法解析，先要确定哈希字面量的基本语法结构：
```go
{<表达式> : <表达式>, <表达式> : <表达式>, ... }
```
AST如下：
```go
//ast.go
// 哈希表
type HashLiteral struct {
	Token token.Token               //"{"
	Pairs map[Expression]Expression //键值对
}

func (hl *HashLiteral) expressionNode()      {}
func (hl *HashLiteral) TokenLiteral() string { return hl.Token.Literal }
func (hl *HashLiteral) String() string {
	var out bytes.Buffer

	pairs := []string{}
	for key, value := range hl.Pairs {
		pairs = append(pairs, key.String()+":"+value.String())
	}

	out.WriteString("{")
	out.WriteString(strings.Join(pairs, ","))
	out.WriteString("}")
	return out.String()
}
```
哈希字面量的解析函数
```go
//parser.go
// 解析哈希表
func (p *Parser) parseHashLiteral() ast.Expression {
	hash := &ast.HashLiteral{Token: p.curToken}
	hash.Pairs = make(map[ast.Expression]ast.Expression)

	for !p.peekTokenIs(token.RBRACE) {
		p.nextToken()
		key := p.parseExpression(LOWEST) //取键值对的键

		if !p.expectPeek(token.COLON) { //遇到:继续，否则说明键值对不完整，退出
			return nil
		}

		p.nextToken()
		value := p.parseExpression(LOWEST) //解析取键值对的值

		hash.Pairs[key] = value //写入键值对
		if !p.peekTokenIs(token.RBRACE) && !p.expectPeek(token.COMMA) {
			return nil
		}
	}

	if !p.expectPeek(token.RBRACE) { //遇到}则退出
		return nil
	}

	return hash
}
```
注册解析函数，很明显是个前缀函数
```go
//parser.go
// 实例化语法分析器
func New(l *lexer.Lexer) *Parser {
	p := &Parser{l: l,
		errors: []string{},
	} //语法分析器实例

	//读取两个词法单元，以设置curToken和peekToken
	p.nextToken()
	p.nextToken()

	//关联解析函数
	//前缀解析函数
	p.prefixParseFns = make(map[token.TokenType]prefixParseFn) //初始化映射
	p.registerPrefix(token.IDENT, p.parseIdentifier)           //注册ident标识符相关的解析函数（parseIdentifier）
	p.registerPrefix(token.INT, p.parseIntegerLiteral)         //注册integer整形相关的解析函数（parseIntegerLiteral）
	p.registerPrefix(token.BANG, p.parsePrefixExpression)      //注册！非的解析函数
	p.registerPrefix(token.MINUS, p.parsePrefixExpression)     //注册-负号的解析函数

	//中缀解析函数
	p.infixParseFns = make(map[token.TokenType]infixParseFn)
	p.registerInfix(token.PLUS, p.parseInfixExpression)     //注册加号+的解析函数
	p.registerInfix(token.MINUS, p.parseInfixExpression)    //注册-负号的解析函数
	p.registerInfix(token.SLASH, p.parseInfixExpression)    //注册/的解析函数
	p.registerInfix(token.ASTERISK, p.parseInfixExpression) //注册*的解析函数
	p.registerInfix(token.EQ, p.parseInfixExpression)       //注册==的解析函数
	p.registerInfix(token.NOT_EQ, p.parseInfixExpression)   //注册!=的解析函数
	p.registerInfix(token.LT, p.parseInfixExpression)       //注册<的解析函数
	p.registerInfix(token.GT, p.parseInfixExpression)       //注册>的解析函数

	//布尔型字面量 前缀表达式
	p.registerPrefix(token.TRUE, p.parseBoolean)
	p.registerPrefix(token.FALSE, p.parseBoolean)

	//分组表达式() 前缀表达式
	p.registerPrefix(token.LPAREN, p.parseGroupedExpression)

	//解析if语句 前缀表达式
	p.registerPrefix(token.IF, p.parseIfExpression)

	//解析函数字面量 前缀表达式
	p.registerPrefix(token.FUNCTION, p.parseFunctionLiteral)

	//解析调用函数表达式
	p.registerInfix(token.LPAREN, p.parseCallExpression) //以左括号为中心，注册一个中缀表达式

	//解析字符串表达式
	p.registerPrefix(token.STRING, p.parseStringLiteral)

	//解析逻辑运算符
	p.registerInfix(token.AND, p.parseInfixExpression)
	p.registerInfix(token.OR, p.parseInfixExpression)

	//解析数组
	p.registerPrefix(token.LBRACKET, p.parseArrayLiteral)

	//解析索引
	p.registerInfix(token.LBRACKET, p.parseIndexExpression)

	//解析哈希表
	p.registerPrefix(token.LBRACE, p.parseHashLiteral)
	return p
}
```
测试代码：
```go
// parser_test.go
// 测试哈希表结构
func TestParsingHashLiteralsStringKeys(t *testing.T) {
	input := `{"one":1,"two":2,"three":3}`

	l := lexer.New(input)
	p := New(l)
	program := p.ParseProgram()
	checkParserErrors(t, p)

	stmt := program.Statements[0].(*ast.ExpressionStatement)
	hash, ok := stmt.Expression.(*ast.HashLiteral)
	if !ok {
		t.Fatalf("exp is not ast.HashLiteral. got=%T", stmt.Expression)
	}

	if len(hash.Pairs) != 3 {
		t.Errorf("hash.Pairs has wrong length. got=%d", len(hash.Pairs))
	}

	expected := map[string]int64{
		"one":   1,
		"two":   2,
		"three": 3,
	}

	for key, value := range hash.Pairs {
		literal, ok := key.(*ast.StringLiteral)
		if !ok {
			t.Errorf("key is not ast.StringLiteral. got=%T", key)
		}

		expecedValue := expected[literal.String()]

		testIntergerLiteral(t, value, expecedValue)
	}
}

// 测试哈希表正确解析
func TestParsingEmptyHashLiteral(t *testing.T) {
	input := `{}`

	l := lexer.New(input)
	p := New(l)
	program := p.ParseProgram()
	checkParserErrors(t, p)

	stmt := program.Statements[0].(*ast.ExpressionStatement)
	hash, ok := stmt.Expression.(*ast.HashLiteral)
	if !ok {
		t.Fatalf("exp is not ast.HashLiteral. got=%T", stmt.Expression)
	}

	if len(hash.Pairs) != 0 {
		t.Errorf("hash.Pairs has wrong length. got=%d", len(hash.Pairs))
	}
}

// 测试哈希表结构
func TestParsingHashLiteralsWithExpressions(t *testing.T) {
	input := `{"one":0+1,"two":10-8,"three":15/5}`

	l := lexer.New(input)
	p := New(l)
	program := p.ParseProgram()
	checkParserErrors(t, p)

	stmt := program.Statements[0].(*ast.ExpressionStatement)
	hash, ok := stmt.Expression.(*ast.HashLiteral)
	if !ok {
		t.Fatalf("exp is not ast.HashLiteral. got=%T", stmt.Expression)
	}

	if len(hash.Pairs) != 3 {
		t.Errorf("hash.Pairs has wrong length. got=%d", len(hash.Pairs))
	}

	tests := map[string]func(ast.Expression){
		"one": func(e ast.Expression) {
			testInfixExpression(t, e, 0, "+", 1)
		},
		"two": func(e ast.Expression) {
			testInfixExpression(t, e, 10, "-", 8)
		},
		"three": func(e ast.Expression) {
			testInfixExpression(t, e, 15, "/", 5)
		},
	}

	for key, value := range hash.Pairs {
		literal, ok := key.(*ast.StringLiteral)
		if !ok {
			t.Errorf("key is not ast.StringLiteral. got=%T", key)
			continue
		}

		testFunc, ok := tests[literal.String()]
		if !ok {
			t.Errorf("No test function for key %q found", literal.String())
		}
		testFunc(value)
	}
}

```
### 1.3 求值
到复杂的地方了。这个哈希表的对象要怎么设计？如果直接使用go的map键值对都设置成object
```go
type Hash struct {
	Pairs map[Object]Object
}
```


## 二、哈希索引

