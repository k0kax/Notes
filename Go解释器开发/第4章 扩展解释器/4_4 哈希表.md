
## 一、哈希字面量
什么是哈希表？在我看来，就是键值对的集合。但是由于算法的约束，有时不同的值会对应相同的键，会造成哈希碰撞。monkey语言的哈希表如下：
```go
>> let myHash = {"name": "Jimmy", "age": 72, "band": "Led Zeppelin"};
>> myHash["name"]
Jimmy
>> myHash["age"]
72
>> myHash["band"]
Led Zeppelin

//又如
>> let myHash = {true: "yes, a boolean", 99: "correct, an integer"};
>> myHash[true]
yes, a boolean
>> myHash[99]
correct, an integer
>> myHash[5 > 1]
yes, a boolean
>> myHash[100 - 1]
correct, an integer
```
### 1.1 词法分析
这个相符简单，只需要在token里加入`:`并且在词法器加入对应的解析即可。
```go
//token.go
// 声明一些词法常量
const (
	// 特殊类型
	ILLEGAL = "ILLEGAL" // 未知字符
	EOF     = "EOF"     // 文件结尾

	// 标识符+字面量
	IDENT = "IDENT" // add, foobar, x, y
	INT   = "INT"   // 1343456

	// 运算符
	ASSIGN   = "="
	PLUS     = "+"
	MINUS    = "-"
	BANG     = "!"
	ASTERISK = "*"
	SLASH    = "/"

	// 分隔符
	COMMA     = ","
	SEMICOLON = ";"

	LT       = "<"
	GT       = ">"
	LPAREN   = "("
	RPAREN   = ")"
	LBRACE   = "{"
	RBRACE   = "}"
	LBRACKET = "["
	RBRACKET = "]"

	// 关键字
	FUNCTION = "FUNCTION"
	LET      = "LET"
	//*********
	IF     = "IF"
	ELIF   = "ELIF"
	ELSE   = "ELSE"
	RETURN = "RETURN"
	TRUE   = "TRUE"
	FALSE  = "FALSE"

	//比较运算符
	EQ     = "=="
	NOT_EQ = "!="

	//字符串
	STRING = "STRING"

	//ToDo
	//逻辑运算符
	AND = "&&" //和
	OR  = "||" //或

	//
	COLON = ":"
)
```
词法器改动如下：
```go
//lexer.go
// 根据当前的ch创建词法单元，匹配对应的Type和字面量Literal
func (l *Lexer) NextToken() token.Token {
	var tok token.Token

	l.skipWhitespace() //跳过空格和一些

	switch l.ch {
	case '=':
		if l.peekChar() == '=' { //特殊处理 等于==
			ch := l.ch
			l.readChar()
			literal := string(ch) + string(l.ch)
			tok = token.Token{Type: token.EQ, Literal: literal}
		} else {
			tok = newToken(token.ASSIGN, l.ch)
		}
	case ';':
		tok = newToken(token.SEMICOLON, l.ch)
	case '(':
		tok = newToken(token.LPAREN, l.ch)
	case ')':
		tok = newToken(token.RPAREN, l.ch)
	case ',':
		tok = newToken(token.COMMA, l.ch)
	case '+':
		tok = newToken(token.PLUS, l.ch)
	case '{':
		tok = newToken(token.LBRACE, l.ch)
	case '}':
		tok = newToken(token.RBRACE, l.ch)
	//！-/*5；
	//			5 < 10 > 5;
	case '!':
		if l.peekChar() == '=' { //特殊处理 不等于！=
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //！=
			tok = token.Token{Type: token.NOT_EQ, Literal: literal}
		} else {
			tok = newToken(token.BANG, l.ch)
		}
	case '-':
		tok = newToken(token.MINUS, l.ch)
	case '*':
		tok = newToken(token.ASTERISK, l.ch)
	case '/':
		tok = newToken(token.SLASH, l.ch)
	case '<':
		tok = newToken(token.LT, l.ch)
	case '>':
		tok = newToken(token.GT, l.ch)

	case 0:
		tok.Literal = ""
		tok.Type = token.EOF

	case '"':
		tok.Type = token.STRING
		tok.Literal = l.readString()

	//Todo
	//逻辑运算符
	case '&': //与运算
		if l.peekChar() == '&' {
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //&&
			tok = token.Token{Type: token.AND, Literal: literal}
		} else {
			tok.Literal = ""
			tok.Type = token.EOF
		}
	case '|': //或运算
		if l.peekChar() == '|' {
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //||
			tok = token.Token{Type: token.OR, Literal: literal}
		} else {
			tok.Literal = ""
			tok.Type = token.EOF
		}
	case '[':
		tok = newToken(token.LBRACKET, l.ch)
	case ']':
		tok = newToken(token.RBRACKET, l.ch)
	case ':':
		tok = newToken(token.COLON, l.ch)

	//检查是否是标识符
	default:
		if isLetter(l.ch) { //判断是否是字母
			tok.Literal = l.readIdentifier()          //字面量indent
			tok.Type = token.LookupIdent(tok.Literal) //检查关键字
			return tok
		} else if isDigit(l.ch) { //检查是否是数字
			tok.Type = token.INT
			tok.Literal = l.readNumber()
			return tok
		} else {
			tok = newToken(token.ILLEGAL, l.ch)
		}
	}

	l.readChar()
	return tok
}
```
测试代码如下：
```go
//lexer_test.go
func TestNextToken(t *testing.T) {
	input := `let five = 5;
let ten = 10;

let add = fn(x, y) {
  x + y;
};

let result = add(five, ten);
!-/*5;
5 < 10 > 5;

if (5 < 10) {
	return true;
} elif(5==10) {
	return false;
}
10 == 10;
10 != 9;
"foobar"
"foo bar"
&&
||
[1,2]
{"foo":"bar"}
`

	tests := []struct {
		expectedType    token.TokenType
		expectedLiteral string
	}{
		{token.LET, "let"},
		{token.IDENT, "five"},
		{token.ASSIGN, "="},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "ten"},
		{token.ASSIGN, "="},
		{token.INT, "10"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "add"},
		{token.ASSIGN, "="},
		{token.FUNCTION, "fn"},
		{token.LPAREN, "("},
		{token.IDENT, "x"},
		{token.COMMA, ","},
		{token.IDENT, "y"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.IDENT, "x"},
		{token.PLUS, "+"},
		{token.IDENT, "y"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "result"},
		{token.ASSIGN, "="},
		{token.IDENT, "add"},
		{token.LPAREN, "("},
		{token.IDENT, "five"},
		{token.COMMA, ","},
		{token.IDENT, "ten"},
		{token.RPAREN, ")"},
		{token.SEMICOLON, ";"},
		{token.BANG, "!"},
		{token.MINUS, "-"},
		{token.SLASH, "/"},
		{token.ASTERISK, "*"},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.INT, "5"},
		{token.LT, "<"},
		{token.INT, "10"},
		{token.GT, ">"},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.IF, "if"},
		{token.LPAREN, "("},
		{token.INT, "5"},
		{token.LT, "<"},
		{token.INT, "10"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RETURN, "return"},
		{token.TRUE, "true"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.ELIF, "elif"},
		{token.LPAREN, "("},
		{token.INT, "5"},
		{token.EQ, "=="},
		{token.INT, "10"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RETURN, "return"},
		{token.FALSE, "false"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.INT, "10"},
		{token.EQ, "=="},
		{token.INT, "10"},
		{token.SEMICOLON, ";"},
		{token.INT, "10"},
		{token.NOT_EQ, "!="},
		{token.INT, "9"},
		{token.SEMICOLON, ";"},
		{token.STRING, "foobar"},
		{token.STRING, "foo bar"},
		{token.AND, "&&"},
		{token.OR, "||"},
		{token.LBRACKET, "["},
		{token.INT, "1"},
		{token.COMMA, ","},
		{token.INT, "2"},
		{token.RBRACKET, "]"},
		{token.LBRACE, "{"},
		{token.STRING, "foo"},
		{token.COLON, ":"},
		{token.STRING, "bar"},
		{token.RBRACE, "}"},
		{token.EOF, ""},
	}

	// 创建词法分析器实例
	l := New(input) //lexer

	//i：表示当前tests中的位置。
	//tt：表示当前迭代的expectedType（词法单元类型）和expectedLiteral（字面量）字段。
	for i, tt := range tests {

		// 调用词法分析器的NextToken方法获取下一个词法单元
		tok := l.NextToken() //token

		// 检查实际的词法单元类型是否与预期的类型一致
		if tok.Type != tt.expectedType {
			t.Fatalf("tests[%d] - tokentype wrong. expected=%q, got==%q", i, tt.expectedType, tok.Type)
		}
		// 检查实际的词法单元字面量是否与预期的字面量一致
		if tok.Literal != tt.expectedLiteral {
			t.Fatalf("tests[%d] - literal wrong. expected=%q, got==%q", i, tt.expectedLiteral, tok.Literal)
		}
	}

}
```
### 1.2 语法分析
语法解析，先要确定哈希字面量的基本语法结构：
```go
{<表达式> : <表达式>, <表达式> : <表达式>, ... }
```
AST如下：
```go
//ast.go
// 哈希表
type HashLiteral struct {
	Token token.Token               //"{"
	Pairs map[Expression]Expression //键值对
}

func (hl *HashLiteral) expressionNode()      {}
func (hl *HashLiteral) TokenLiteral() string { return hl.Token.Literal }
func (hl *HashLiteral) String() string {
	var out bytes.Buffer

	pairs := []string{}
	for key, value := range hl.Pairs {
		pairs = append(pairs, key.String()+":"+value.String())
	}

	out.WriteString("{")
	out.WriteString(strings.Join(pairs, ","))
	out.WriteString("}")
	return out.String()
}
```
哈希字面量的解析函数
```go
//parser.go

```
### 1.3 求值

## 二、哈希索引

