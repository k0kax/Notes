## 词法解析
新建数组token
```go
//token.go
// 声明一些词法常量
const (
	// 特殊类型
	ILLEGAL = "ILLEGAL" // 未知字符
	EOF     = "EOF"     // 文件结尾

	// 标识符+字面量
	IDENT = "IDENT" // add, foobar, x, y
	INT   = "INT"   // 1343456

	// 运算符
	ASSIGN   = "="
	PLUS     = "+"
	MINUS    = "-"
	BANG     = "!"
	ASTERISK = "*"
	SLASH    = "/"

	// 分隔符
	COMMA     = ","
	SEMICOLON = ";"

	LT       = "<"
	GT       = ">"
	LPAREN   = "("
	RPAREN   = ")"
	LBRACE   = "{"
	RBRACE   = "}"
	LBRACKET = "["
	RBRACKET = "]"

	// 关键字
	FUNCTION = "FUNCTION"
	LET      = "LET"
	//*********
	IF     = "IF"
	ELIF   = "ELIF"
	ELSE   = "ELSE"
	RETURN = "RETURN"
	TRUE   = "TRUE"
	FALSE  = "FALSE"

	//比较运算符
	EQ     = "=="
	NOT_EQ = "!="

	//字符串
	STRING = "STRING"

	//ToDo
	//逻辑运算符
	AND = "&&" //和
	OR  = "||" //或
)
```
修改词法器，解释数组的`[]`
```go
// lexer.go
// 根据当前的ch创建词法单元，匹配对应的Type和字面量Literal
func (l *Lexer) NextToken() token.Token {
	var tok token.Token

	l.skipWhitespace() //跳过空格和一些

	switch l.ch {
	case '=':
		if l.peekChar() == '=' { //特殊处理 等于==
			ch := l.ch
			l.readChar()
			literal := string(ch) + string(l.ch)
			tok = token.Token{Type: token.EQ, Literal: literal}
		} else {
			tok = newToken(token.ASSIGN, l.ch)
		}
	case ';':
		tok = newToken(token.SEMICOLON, l.ch)
	case '(':
		tok = newToken(token.LPAREN, l.ch)
	case ')':
		tok = newToken(token.RPAREN, l.ch)
	case ',':
		tok = newToken(token.COMMA, l.ch)
	case '+':
		tok = newToken(token.PLUS, l.ch)
	case '{':
		tok = newToken(token.LBRACE, l.ch)
	case '}':
		tok = newToken(token.RBRACE, l.ch)
	//！-/*5；
	//			5 < 10 > 5;
	case '!':
		if l.peekChar() == '=' { //特殊处理 不等于！=
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //！=
			tok = token.Token{Type: token.NOT_EQ, Literal: literal}
		} else {
			tok = newToken(token.BANG, l.ch)
		}
	case '-':
		tok = newToken(token.MINUS, l.ch)
	case '*':
		tok = newToken(token.ASTERISK, l.ch)
	case '/':
		tok = newToken(token.SLASH, l.ch)
	case '<':
		tok = newToken(token.LT, l.ch)
	case '>':
		tok = newToken(token.GT, l.ch)

	case 0:
		tok.Literal = ""
		tok.Type = token.EOF

	case '"':
		tok.Type = token.STRING
		tok.Literal = l.readString()

	//Todo
	//逻辑运算符
	case '&': //与运算
		if l.peekChar() == '&' {
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //&&
			tok = token.Token{Type: token.AND, Literal: literal}
		} else {
			tok.Literal = ""
			tok.Type = token.EOF
		}
	case '|': //或运算
		if l.peekChar() == '|' {
			ch := l.ch //获取当前字符
			l.readChar()
			literal := string(ch) + string(l.ch) //||
			tok = token.Token{Type: token.OR, Literal: literal}
		} else {
			tok.Literal = ""
			tok.Type = token.EOF
		}
	case '[':
		tok = newToken(token.LBRACKET, l.ch)
	case ']':
		tok = newToken(token.RBRACKET, l.ch)

	//检查是否是标识符
	default:
		if isLetter(l.ch) { //判断是否是字母
			tok.Literal = l.readIdentifier()          //字面量indent
			tok.Type = token.LookupIdent(tok.Literal) //检查关键字
			return tok
		} else if isDigit(l.ch) { //检查是否是数字
			tok.Type = token.INT
			tok.Literal = l.readNumber()
			return tok
		} else {
			tok = newToken(token.ILLEGAL, l.ch)
		}
	}

	l.readChar()
	return tok
}
```
测试代码：
```go
//lexer_test.go
func TestNextToken(t *testing.T) {
	input := `let five = 5;
let ten = 10;

let add = fn(x, y) {
  x + y;
};

let result = add(five, ten);
!-/*5;
5 < 10 > 5;

if (5 < 10) {
	return true;
} elif(5==10) {
	return false;
}
10 == 10;
10 != 9;
"foobar"
"foo bar"
&&
||
[1,2]
`

	tests := []struct {
		expectedType    token.TokenType
		expectedLiteral string
	}{
		{token.LET, "let"},
		{token.IDENT, "five"},
		{token.ASSIGN, "="},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "ten"},
		{token.ASSIGN, "="},
		{token.INT, "10"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "add"},
		{token.ASSIGN, "="},
		{token.FUNCTION, "fn"},
		{token.LPAREN, "("},
		{token.IDENT, "x"},
		{token.COMMA, ","},
		{token.IDENT, "y"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.IDENT, "x"},
		{token.PLUS, "+"},
		{token.IDENT, "y"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.SEMICOLON, ";"},
		{token.LET, "let"},
		{token.IDENT, "result"},
		{token.ASSIGN, "="},
		{token.IDENT, "add"},
		{token.LPAREN, "("},
		{token.IDENT, "five"},
		{token.COMMA, ","},
		{token.IDENT, "ten"},
		{token.RPAREN, ")"},
		{token.SEMICOLON, ";"},
		{token.BANG, "!"},
		{token.MINUS, "-"},
		{token.SLASH, "/"},
		{token.ASTERISK, "*"},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.INT, "5"},
		{token.LT, "<"},
		{token.INT, "10"},
		{token.GT, ">"},
		{token.INT, "5"},
		{token.SEMICOLON, ";"},
		{token.IF, "if"},
		{token.LPAREN, "("},
		{token.INT, "5"},
		{token.LT, "<"},
		{token.INT, "10"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RETURN, "return"},
		{token.TRUE, "true"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.ELIF, "elif"},
		{token.LPAREN, "("},
		{token.INT, "5"},
		{token.EQ, "=="},
		{token.INT, "10"},
		{token.RPAREN, ")"},
		{token.LBRACE, "{"},
		{token.RETURN, "return"},
		{token.FALSE, "false"},
		{token.SEMICOLON, ";"},
		{token.RBRACE, "}"},
		{token.INT, "10"},
		{token.EQ, "=="},
		{token.INT, "10"},
		{token.SEMICOLON, ";"},
		{token.INT, "10"},
		{token.NOT_EQ, "!="},
		{token.INT, "9"},
		{token.SEMICOLON, ";"},
		{token.STRING, "foobar"},
		{token.STRING, "foo bar"},
		{token.AND, "&&"},
		{token.OR, "||"},
		{token.LBRACKET, "["},
		{token.INT, "1"},
		{token.COMMA, ","},
		{token.INT, "2"},
		{token.RBRACKET, "]"},
		{token.EOF, ""},
	}

	// 创建词法分析器实例
	l := New(input) //lexer

	//i：表示当前tests中的位置。
	//tt：表示当前迭代的expectedType（词法单元类型）和expectedLiteral（字面量）字段。
	for i, tt := range tests {

		// 调用词法分析器的NextToken方法获取下一个词法单元
		tok := l.NextToken() //token

		// 检查实际的词法单元类型是否与预期的类型一致
		if tok.Type != tt.expectedType {
			t.Fatalf("tests[%d] - tokentype wrong. expected=%q, got==%q", i, tt.expectedType, tok.Type)
		}
		// 检查实际的词法单元字面量是否与预期的字面量一致
		if tok.Literal != tt.expectedLiteral {
			t.Fatalf("tests[%d] - literal wrong. expected=%q, got==%q", i, tt.expectedLiteral, tok.Literal)
		}
	}

}

```

## 语法分析
新建数组的ast
```go
//ast.go
// 数组
type ArrayLiteral struct {
	Token    token.Token
	Elements []Expression//数组内元素
}

func (al *ArrayLiteral) expressionNode()      {}
func (al *ArrayLiteral) TokenLiteral() string { return al.Token.Literal }
func (al *ArrayLiteral) String() string {
	var out bytes.Buffer

	elements := []string{}
	for _, el := range al.Elements {
		elements = append(elements, el.String())
	}

	out.WriteString("[")
	out.WriteString(strings.Join(elements, ","))
	out.WriteString("]")

	return out.String()
}
```
在语法解析器中加入对应的解析函数
```go
//parser.go
// 实例化语法分析器
func New(l *lexer.Lexer) *Parser {
	p := &Parser{l: l,
		errors: []string{},
	} //语法分析器实例

	//读取两个词法单元，以设置curToken和peekToken
	p.nextToken()
	p.nextToken()

	//关联解析函数
	//前缀解析函数
	p.prefixParseFns = make(map[token.TokenType]prefixParseFn) //初始化映射
	p.registerPrefix(token.IDENT, p.parseIdentifier)           //注册ident标识符相关的解析函数（parseIdentifier）
	p.registerPrefix(token.INT, p.parseIntegerLiteral)         //注册integer整形相关的解析函数（parseIntegerLiteral）
	p.registerPrefix(token.BANG, p.parsePrefixExpression)      //注册！非的解析函数
	p.registerPrefix(token.MINUS, p.parsePrefixExpression)     //注册-负号的解析函数

	//中缀解析函数
	p.infixParseFns = make(map[token.TokenType]infixParseFn)
	p.registerInfix(token.PLUS, p.parseInfixExpression)     //注册加号+的解析函数
	p.registerInfix(token.MINUS, p.parseInfixExpression)    //注册-负号的解析函数
	p.registerInfix(token.SLASH, p.parseInfixExpression)    //注册/的解析函数
	p.registerInfix(token.ASTERISK, p.parseInfixExpression) //注册*的解析函数
	p.registerInfix(token.EQ, p.parseInfixExpression)       //注册==的解析函数
	p.registerInfix(token.NOT_EQ, p.parseInfixExpression)   //注册!=的解析函数
	p.registerInfix(token.LT, p.parseInfixExpression)       //注册<的解析函数
	p.registerInfix(token.GT, p.parseInfixExpression)       //注册>的解析函数

	//布尔型字面量 前缀表达式
	p.registerPrefix(token.TRUE, p.parseBoolean)
	p.registerPrefix(token.FALSE, p.parseBoolean)

	//分组表达式() 前缀表达式
	p.registerPrefix(token.LPAREN, p.parseGroupedExpression)

	//解析if语句 前缀表达式
	p.registerPrefix(token.IF, p.parseIfExpression)

	//解析函数字面量 前缀表达式
	p.registerPrefix(token.FUNCTION, p.parseFunctionLiteral)

	//解析调用函数表达式
	p.registerInfix(token.LPAREN, p.parseCallExpression) //以左括号为中心，注册一个中缀表达式

	//解析字符串表达式
	p.registerPrefix(token.STRING, p.parseStringLiteral)

	//解析逻辑运算符
	p.registerInfix(token.AND, p.parseInfixExpression)
	p.registerInfix(token.OR, p.parseInfixExpression)

	//解析数组
	p.registerPrefix(token.LBRACKET, p.parseArrayLiteral)

	// 解析索引
	p.registerInfix(token.LBRACKET, p.parseIndexExpression)
	return p
}

// 解析数组
func (p *Parser) parseArrayLiteral() ast.Expression {
	array := &ast.ArrayLiteral{Token: p.curToken}

	array.Elements = p.parseExpressionList(token.RBRACKET) //遇到]结束

	return array
}
```
由于数组是一个列表，解析它的每一个元素，还需要一个新元素
```go
//parser.go
func (p *Parser) parseExpressionList(end token.TokenType) []ast.Expression {
	list := []ast.Expression{}

	if p.peekTokenIs(end) {
		p.nextToken()
		return list
	}

	p.nextToken()
	list = append(list, p.parseExpression(LOWEST))

	for p.peekTokenIs(token.COMMA) {
		p.nextToken()
		p.nextToken()
		list = append(list, p.parseExpression(LOWEST))
	}

	if !p.expectPeek(end) {
		return nil
	}

	return list
}
```




repl测试
```go
Feel freee to type in commamds
>>let a = [1, 2, 3, 4];
>> let b = push(a, 5);
>>a
[1,2,3,4]
>>b
[1,2,3,4,5]
>>
```
